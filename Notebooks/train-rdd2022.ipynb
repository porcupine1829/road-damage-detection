{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48da0d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:06:11.306232Z",
     "iopub.status.busy": "2025-04-03T11:06:11.305868Z",
     "iopub.status.idle": "2025-04-03T11:06:11.310414Z",
     "shell.execute_reply": "2025-04-03T11:06:11.309713Z"
    },
    "papermill": {
     "duration": 0.00885,
     "end_time": "2025-04-03T11:06:11.311614",
     "exception": false,
     "start_time": "2025-04-03T11:06:11.302764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c405d680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:06:11.315494Z",
     "iopub.status.busy": "2025-04-03T11:06:11.315287Z",
     "iopub.status.idle": "2025-04-03T11:06:17.567131Z",
     "shell.execute_reply": "2025-04-03T11:06:17.566447Z"
    },
    "papermill": {
     "duration": 6.255193,
     "end_time": "2025-04-03T11:06:17.568604",
     "exception": false,
     "start_time": "2025-04-03T11:06:11.313411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6157f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T11:06:17.573235Z",
     "iopub.status.busy": "2025-04-03T11:06:17.572854Z",
     "iopub.status.idle": "2025-04-03T17:36:58.068303Z",
     "shell.execute_reply": "2025-04-03T17:36:58.067247Z"
    },
    "papermill": {
     "duration": 23440.499325,
     "end_time": "2025-04-03T17:36:58.069793",
     "exception": false,
     "start_time": "2025-04-03T11:06:17.570468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Ultralytics 8.3.100 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/train-rdd2022/weights/road_damage_model.pt, data=/kaggle/input/rdd-2022/RDD-2022/dataset.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=/kaggle/working/, name=road_damage_detector, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/road_damage_detector\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 34.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8721820  ultralytics.nn.modules.head.Detect           [4, [320, 640, 640]]          \n",
      "Model summary: 209 layers, 68,156,460 parameters, 68,156,444 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 595/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /kaggle/working/road_damage_detector', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 164MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/rdd-2022/RDD-2022/train/labels... 12734 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12734/12734 [01:00<00:00, 210.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/rdd-2022/RDD-2022/train is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/rdd-2022/RDD-2022/test/labels... 3194 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3194/3194 [00:15<00:00, 208.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/rdd-2022/RDD-2022/test is not writeable, cache not saved.\n",
      "Plotting labels to /kaggle/working/road_damage_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/road_damage_detector\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.6G      1.755      1.994      1.742         41        640: 100%|██████████| 796/796 [17:58<00:00,  1.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:33<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.418      0.387      0.355      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.7G      1.829      2.137      1.794         54        640: 100%|██████████| 796/796 [17:48<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.402      0.378      0.333      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.7G       1.85      2.156      1.804         54        640: 100%|██████████| 796/796 [17:46<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.428      0.385      0.369      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      13.7G      1.836       2.14       1.79         41        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.454      0.391      0.377      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      13.7G      1.799      2.063      1.752         44        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.451      0.442      0.413      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      13.7G      1.783      2.015       1.74         47        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.496       0.44      0.433      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      13.7G      1.758       1.97      1.722         57        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.481      0.419      0.406      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      13.7G      1.725      1.917      1.693         40        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.511       0.46      0.457      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      13.7G      1.715      1.883      1.691         42        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.528      0.476      0.479      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      13.7G      1.706      1.854      1.686         49        640: 100%|██████████| 796/796 [17:45<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.533      0.487      0.492      0.233\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.7G      1.707      1.809      1.734         30        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.539      0.498      0.505      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      13.7G       1.69      1.751      1.719         33        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.547      0.508      0.515      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      13.7G      1.673      1.714       1.71         28        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.542      0.521      0.525      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      13.7G      1.643      1.668      1.696         28        640: 100%|██████████| 796/796 [17:45<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900       0.57      0.521      0.539      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      13.7G      1.629      1.624      1.682         36        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.579       0.53      0.557      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      13.7G      1.612      1.582      1.676         34        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.573       0.54       0.56       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      13.7G      1.592      1.546      1.658         19        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900       0.59      0.547      0.573      0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      13.7G      1.574      1.503      1.641         33        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.587      0.559      0.579      0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      13.7G      1.552      1.472      1.634         37        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.596      0.564      0.586      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      13.7G      1.536      1.442      1.615         26        640: 100%|██████████| 796/796 [17:44<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:31<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.605       0.56      0.589      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 6.443 hours.\n",
      "Optimizer stripped from /kaggle/working/road_damage_detector/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from /kaggle/working/road_damage_detector/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating /kaggle/working/road_damage_detector/weights/best.pt...\n",
      "Ultralytics 8.3.100 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "Model summary (fused): 112 layers, 68,127,420 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 100/100 [01:34<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3194       6900      0.606       0.56      0.589      0.299\n",
      "                   D00       1541       2457        0.6      0.634       0.64      0.351\n",
      "                   D10        964       1537      0.555      0.523      0.526      0.247\n",
      "                   D20       1425       1794      0.666      0.609      0.666      0.363\n",
      "                   D40        594       1112      0.602      0.473      0.524      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.2ms preprocess, 26.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/road_damage_detector\u001b[0m\n",
      "Best model saved to /kaggle/working/weights/road_damage_model.pt\n"
     ]
    }
   ],
   "source": [
    "def train_model(dataset_yaml, model_path=\"yolov8x\", img_size=640, batch_size=32, epochs=50, output_dir=\"/kaggle/working\"):\n",
    "    \"\"\"\n",
    "    Train a YOLOv8x model on the road damage dataset\n",
    "\n",
    "    Args:\n",
    "        dataset_yaml: Path to the dataset yaml file\n",
    "        model_path: Base model name (e.g., \"yolov8x\") or path to a .pt file\n",
    "        epochs: Number of training epochs\n",
    "        img_size: Image size for training\n",
    "        batch_size: Batch size for training\n",
    "        output_dir: Directory to save outputs\n",
    "    \"\"\"\n",
    "    # Set up GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Model path for outputs\n",
    "    weights_dir = os.path.join(output_dir, \"weights\")\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Save training configuration for future reference\n",
    "    config = {\n",
    "        \"dataset_yaml\": dataset_yaml,\n",
    "        \"model_path\": model_path,\n",
    "        \"epochs\": epochs,\n",
    "        \"img_size\": img_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"device\": str(device),\n",
    "        \"accelerator\": \"gpu\",\n",
    "    }\n",
    "\n",
    "    config_path = os.path.join(output_dir, \"training_config.json\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "    # Prepare training arguments\n",
    "    train_args = {\n",
    "        'data': dataset_yaml,\n",
    "        'epochs': epochs,\n",
    "        'imgsz': img_size,\n",
    "        'batch': batch_size,\n",
    "        'project': output_dir,\n",
    "        'name': \"road_damage_detector\",\n",
    "        'verbose': True,\n",
    "        'workers': 2,  # More workers for data loading\n",
    "        'cache': False,  # Cache data for faster training\n",
    "        'device': str(device)\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    model.train(**train_args)\n",
    "\n",
    "    # Get the path to the best model\n",
    "    best_model_path = os.path.join(output_dir, \"road_damage_detector\", \"weights\", \"best.pt\")\n",
    "\n",
    "    # Save a copy to a more accessible location\n",
    "    if os.path.exists(best_model_path):\n",
    "        final_model_path = os.path.join(weights_dir, \"road_damage_model.pt\")\n",
    "        shutil.copy(best_model_path, final_model_path)\n",
    "        print(f\"Best model saved to {final_model_path}\")\n",
    "\n",
    "        # Save training checkpoint information\n",
    "        checkpoint_info = {\n",
    "            \"model_path\": final_model_path,\n",
    "            \"training_completed\": True,\n",
    "            \"epochs_completed\": epochs\n",
    "        }\n",
    "\n",
    "        checkpoint_file = os.path.join(output_dir, \"training_checkpoint.json\")\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint_info, f, indent=4)\n",
    "\n",
    "        return final_model_path\n",
    "    else:\n",
    "        print(f\"Warning: Best model not found at {best_model_path}\")\n",
    "        # Try to find any model weights that might have been saved\n",
    "        model_files = glob.glob(os.path.join(output_dir, \"road_damage_detector/weights/*.pt\"))\n",
    "        if model_files:\n",
    "            latest_model = sorted(model_files, key=os.path.getmtime)[-1]\n",
    "            print(f\"Found alternative model file: {latest_model}\")\n",
    "            final_model_path = os.path.join(weights_dir, \"road_damage_model.pt\")\n",
    "            shutil.copy(latest_model, final_model_path)\n",
    "\n",
    "            # Save partial training checkpoint\n",
    "            checkpoint_info = {\n",
    "                \"model_path\": final_model_path,\n",
    "                \"model_source\": latest_model,\n",
    "                \"training_completed\": False\n",
    "            }\n",
    "\n",
    "            checkpoint_file = os.path.join(output_dir, \"training_checkpoint.json\")\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint_info, f, indent=4)\n",
    "\n",
    "            return final_model_path\n",
    "\n",
    "        # Save failed training information\n",
    "        checkpoint_info = {\n",
    "            \"model_path\": None,\n",
    "            \"training_completed\": False,\n",
    "            \"error\": \"No model weights found\"\n",
    "        }\n",
    "\n",
    "        checkpoint_file = os.path.join(output_dir, \"training_checkpoint.json\")\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint_info, f, indent=4)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/input/train-rdd2022/weights/road_damage_model.pt\"\n",
    "dataset_yaml = \"/kaggle/input/rdd-2022/RDD-2022/dataset.yaml\"\n",
    "work_dir = \"/kaggle/working/\"\n",
    "\n",
    "# Train the model\n",
    "model_path = train_model(\n",
    "    dataset_yaml=dataset_yaml,\n",
    "    model_path=model_path,  # Base model name or path\n",
    "    output_dir=work_dir,\n",
    "    batch_size=16,\n",
    "    img_size=640,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90f9be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:37:01.581097Z",
     "iopub.status.busy": "2025-04-03T17:37:01.580736Z",
     "iopub.status.idle": "2025-04-03T17:37:01.585047Z",
     "shell.execute_reply": "2025-04-03T17:37:01.584169Z"
    },
    "papermill": {
     "duration": 1.776176,
     "end_time": "2025-04-03T17:37:01.586325",
     "exception": false,
     "start_time": "2025-04-03T17:36:59.810149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/weights/road_damage_model.pt\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7036838,
     "sourceId": 11259207,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231486915,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23458.302431,
   "end_time": "2025-04-03T17:37:07.030220",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-03T11:06:08.727789",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
